import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.linear_model import Ridge, LinearRegression
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error
from sklearn.pipeline import Pipeline
import warnings
warnings.filterwarnings('ignore')

# ==================== ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ====================
def load_and_prepare_data(file_path):
    """ØªØ­Ù…ÙŠÙ„ ÙˆÙ…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"""
    print("ğŸ“Š ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª...")
    df = pd.read_csv(file_path)
    
    print(f"Ø¹Ø¯Ø¯ Ø§Ù„ØµÙÙˆÙ Ø§Ù„Ø£ØµÙ„ÙŠØ©: {len(df)}")
    print(f"\n Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù…ØªØ§Ø­Ø©:\n{df.columns.tolist()}")
    
    # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ØµÙÙˆÙ Ø§Ù„ØªÙŠ ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ù‚ÙŠÙ… ÙØ§Ø±ØºØ© ÙÙŠ Ø§Ù„Ù…ØªØºÙŠØ± Ø§Ù„ØªØ§Ø¨Ø¹ (delay_minutes_corrected)
    df_clean = df.dropna(subset=['delay_minutes_corrected']).copy()
    print(f"Ø¹Ø¯Ø¯ Ø§Ù„ØµÙÙˆÙ Ø¨Ø¹Ø¯ Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ÙØ§Ø±ØºØ©: {len(df_clean)}")
    
    # Ù…Ù„Ø¡ Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„ÙØ§Ø±ØºØ© ÙÙŠ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ø£Ø®Ø±Ù‰
    df_clean['prev_delay'] = df_clean['prev_delay'].fillna(0)
    
    # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ØµÙÙˆÙ Ø§Ù„ØªÙŠ ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ infinity Ø£Ùˆ Ù‚ÙŠÙ… ÙƒØ¨ÙŠØ±Ø© Ø¬Ø¯Ø§Ù‹
    df_clean = df_clean.replace([np.inf, -np.inf], np.nan)
    df_clean = df_clean.dropna()
    
    # Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…ÙŠØ²Ø§Øª Ø§Ù„Ø²Ù…Ù†ÙŠØ© Ø§Ù„Ø¥Ø¶Ø§ÙÙŠØ©
    df_clean['scheduled_datetime'] = pd.to_datetime(df_clean['scheduled_date'])
    df_clean['day_of_week'] = df_clean['scheduled_datetime'].dt.dayofweek
    df_clean['month'] = df_clean['scheduled_datetime'].dt.month
    df_clean['is_weekend'] = (df_clean['day_of_week'] >= 5).astype(int)
    
    # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„ÙØ¦ÙˆÙŠØ©
    categorical_cols = ['time_category_en', 'day_period', 'weather_en', 
                       'passenger_level', 'rush_period', 'delay_status_en']
    
    label_encoders = {}
    for col in categorical_cols:
        if col in df_clean.columns:
            le = LabelEncoder()
            df_clean[f'{col}_encoded'] = le.fit_transform(df_clean[col].fillna('Unknown'))
            label_encoders[col] = le
    
    return df_clean, label_encoders

# ==================== ØªØ­Ø¶ÙŠØ± Ø§Ù„Ù…ÙŠØ²Ø§Øª ====================
def prepare_features(df, label_encoders):
    """ØªØ­Ø¶ÙŠØ± Ø§Ù„Ù…ÙŠØ²Ø§Øª Ø§Ù„Ù…Ù†Ø§Ø³Ø¨Ø© Ù„Ù„Ù†Ù…ÙˆØ°Ø¬"""
    print("\nğŸ”§ ØªØ­Ø¶ÙŠØ± Ø§Ù„Ù…ÙŠØ²Ø§Øª...")
    
    # Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ù…ÙŠØ²Ø§Øª Ø°Ø§Øª Ø§Ù„ØµÙ„Ø©y
    feature_cols = [
        'hour', 'day_of_week', 'month', 'is_weekend', 'day_period_encoded',
        'time_category_en_encoded', 'passenger_count_final', 'passenger_load_index',
        'prev_delay', 'rush_period', 'route_frequency', 'speed_proxy',
        'weather_severity', 'distance_change', 'latitude_clean', 'longitude_clean',
        'weather_en_encoded', 'passenger_level_encoded'
    ]
    
    # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„ØªÙŠ Ù„Ø§ ØªÙˆØ¬Ø¯ ÙÙŠ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
    feature_cols = [col for col in feature_cols if col in df.columns]
    
    X = df[feature_cols].fillna(df[feature_cols].mean())
    y = df['delay_minutes_corrected']
    
    print(f"Ø¹Ø¯Ø¯ Ø§Ù„Ù…ÙŠØ²Ø§Øª: {len(feature_cols)}")
    print(f"Ø§Ù„Ù…ÙŠØ²Ø§Øª Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…Ø©: {feature_cols}")
    
    return X, y, feature_cols

# ==================== Ø¨Ù†Ø§Ø¡ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ ====================
def build_models(X_train, X_test, y_train, y_test):
    """Ø¨Ù†Ø§Ø¡ ÙˆØªØ¯Ø±ÙŠØ¨ Ø¹Ø¯Ø© Ù†Ù…Ø§Ø°Ø¬ Ù…Ø®ØªÙ„ÙØ©"""
    print("\nğŸ¤– Ø¨Ù†Ø§Ø¡ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬...")
    
    models = {
        'Random Forest': RandomForestRegressor(n_estimators=100, max_depth=20, 
                                               random_state=42, n_jobs=-1),
        'Gradient Boosting': GradientBoostingRegressor(n_estimators=100, 
                                                       learning_rate=0.1, 
                                                       max_depth=5, random_state=42),
        'Ridge Regression': Ridge(alpha=1.0),
        'Linear Regression': LinearRegression()
    }
    
    results = {}
    
    for name, model in models.items():
        print(f"\n  ğŸ“ ØªØ¯Ø±ÙŠØ¨ {name}...")
        
        # Ø¥Ù†Ø´Ø§Ø¡ Pipeline Ù…Ø¹ ØªØ·Ø¨ÙŠØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        pipeline = Pipeline([
            ('scaler', StandardScaler()),
            ('model', model)
        ])
        
        # ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
        pipeline.fit(X_train, y_train)
        
        # Ø§Ù„ØªÙ†Ø¨Ø¤
        y_pred_train = pipeline.predict(X_train)
        y_pred_test = pipeline.predict(X_test)
        
        # Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ù‚Ø§ÙŠÙŠØ³
        train_mse = mean_squared_error(y_train, y_pred_train)
        test_mse = mean_squared_error(y_test, y_pred_test)
        train_r2 = r2_score(y_train, y_pred_train)
        test_r2 = r2_score(y_test, y_pred_test)
        test_mae = mean_absolute_error(y_test, y_pred_test)
        test_rmse = np.sqrt(test_mse)
        
        results[name] = {
            'model': pipeline,
            'train_r2': train_r2,
            'test_r2': test_r2,
            'train_mse': train_mse,
            'test_mse': test_mse,
            'test_mae': test_mae,
            'test_rmse': test_rmse,
            'predictions': y_pred_test
        }
        
        print(f"    âœ“ Train RÂ²: {train_r2:.4f}")
        print(f"    âœ“ Test RÂ²: {test_r2:.4f}")
        print(f"    âœ“ Test RMSE: {test_rmse:.4f}")
        print(f"    âœ“ Test MAE: {test_mae:.4f}")
    
    return results

# ==================== Ø¹Ø±Ø¶ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ ====================
def print_results(results):
    """Ø¹Ø±Ø¶ Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ù†ØªØ§Ø¦Ø¬"""
    print("\n" + "="*70)
    print("ğŸ“Š Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ù†Ù…Ø§Ø°Ø¬")
    print("="*70)
    
    results_df = pd.DataFrame({
        model_name: {
            'Train RÂ²': result['train_r2'],
            'Test RÂ²': result['test_r2'],
            'Test RMSE': result['test_rmse'],
            'Test MAE': result['test_mae']
        }
        for model_name, result in results.items()
    }).T
    
    print(results_df.to_string())
    print("\nâœ… Ø£ÙØ¶Ù„ Ù†Ù…ÙˆØ°Ø¬:", results_df['Test RÂ²'].idxmax())
    
    return results_df

# ==================== ØªØµÙˆØ± Ø§Ù„Ù†ØªØ§Ø¦Ø¬ ====================
def visualize_results(results, y_test):
    """Ø±Ø³Ù… Ø§Ù„Ù†ØªØ§Ø¦Ø¬"""
    print("\nğŸ“ˆ Ø±Ø³Ù… Ø§Ù„Ù†ØªØ§Ø¦Ø¬...")
    
    fig, axes = plt.subplots(2, 2, figsize=(14, 10))
    fig.suptitle('Ù…Ù‚Ø§Ø±Ù†Ø© Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¨Ø±Ø­Ù„Ø§Øª Ø§Ù„ØªØ£Ø®ÙŠØ±', fontsize=16, fontweight='bold')
    
    for idx, (name, result) in enumerate(results.items()):
        ax = axes[idx // 2, idx % 2]
        
        predictions = result['predictions']
        ax.scatter(y_test, predictions, alpha=0.5, s=20)
        ax.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 
                'r--', lw=2, label='Perfect Prediction')
        
        ax.set_xlabel('Ø§Ù„Ù‚ÙŠÙ…Ø© Ø§Ù„ÙØ¹Ù„ÙŠØ© Ù„Ù„ØªØ£Ø®ÙŠØ± (Ø¯Ù‚Ø§Ø¦Ù‚)')
        ax.set_ylabel('Ø§Ù„Ù‚ÙŠÙ…Ø© Ø§Ù„Ù…ØªÙ†Ø¨Ø£ Ø¨Ù‡Ø§ (Ø¯Ù‚Ø§Ø¦Ù‚)')
        ax.set_title(f'{name}\nRÂ² = {result["test_r2"]:.4f}')
        ax.legend()
        ax.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.savefig(r'c:\Users\gerge\OneDrive\Ø³Ø·Ø­ Ø§Ù„Ù…ÙƒØªØ¨\VSCODE\c++\AI\model_comparison.png', dpi=300, bbox_inches='tight')
    print("âœ“ ØªÙ… Ø­ÙØ¸ Ø§Ù„Ø±Ø³Ù… ÙÙŠ 'model_comparison.png'")
    plt.show()

# ==================== ØªØ­Ù„ÙŠÙ„ Ø£Ù‡Ù…ÙŠØ© Ø§Ù„Ù…ÙŠØ²Ø§Øª ====================
def feature_importance(results, feature_cols):
    """Ø¹Ø±Ø¶ Ø£Ù‡Ù…ÙŠØ© Ø§Ù„Ù…ÙŠØ²Ø§Øª"""
    print("\nğŸ¯ Ø£Ù‡Ù…ÙŠØ© Ø§Ù„Ù…ÙŠØ²Ø§Øª (Ù„Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø£ÙØ¶Ù„):")
    
    # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø£ÙØ¶Ù„ Ù†Ù…ÙˆØ°Ø¬
    best_model_name = max(results, key=lambda x: results[x]['test_r2'])
    best_model = results[best_model_name]['model']
    
    # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ feature_importances_
    if hasattr(best_model.named_steps['model'], 'feature_importances_'):
        importances = best_model.named_steps['model'].feature_importances_
        feature_importance_df = pd.DataFrame({
            'Ø§Ù„Ù…ÙŠØ²Ø©': feature_cols,
            'Ø§Ù„Ø£Ù‡Ù…ÙŠØ©': importances
        }).sort_values('Ø§Ù„Ø£Ù‡Ù…ÙŠØ©', ascending=False)
        
        print(feature_importance_df.head(10).to_string(index=False))
        
        # Ø±Ø³Ù… Ø£Ù‡Ù…ÙŠØ© Ø§Ù„Ù…ÙŠØ²Ø§Øª
        fig, ax = plt.subplots(figsize=(10, 6))
        top_features = feature_importance_df.head(10)
        ax.barh(range(len(top_features)), top_features['Ø§Ù„Ø£Ù‡Ù…ÙŠØ©'].values)
        ax.set_yticks(range(len(top_features)))
        ax.set_yticklabels(top_features['Ø§Ù„Ù…ÙŠØ²Ø©'].values)
        ax.set_xlabel('Ø¯Ø±Ø¬Ø© Ø§Ù„Ø£Ù‡Ù…ÙŠØ©')
        ax.set_title(f'Ø£Ù‡Ù…ÙŠØ© Ø§Ù„Ù…ÙŠØ²Ø§Øª - {best_model_name}')
        plt.tight_layout()
        plt.savefig(r'c:\Users\gerge\OneDrive\Ø³Ø·Ø­ Ø§Ù„Ù…ÙƒØªØ¨\VSCODE\c++\AI\feature_importance.png', dpi=300, bbox_inches='tight')
        print("âœ“ ØªÙ… Ø­ÙØ¸ Ø±Ø³Ù… Ø§Ù„Ù…ÙŠØ²Ø§Øª ÙÙŠ 'feature_importance.png'")
        plt.show()

# ==================== Ø§Ù„Ø¯Ø§Ù„Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© ====================
def main():
    # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
    file_path = r'c:\Users\gerge\OneDrive\Ø³Ø·Ø­ Ø§Ù„Ù…ÙƒØªØ¨\VSCODE\c++\AI\dataset_with_features.csv'
    df, label_encoders = load_and_prepare_data(file_path)
    
    # ØªØ­Ø¶ÙŠØ± Ø§Ù„Ù…ÙŠØ²Ø§Øª
    X, y, feature_cols = prepare_features(df, label_encoders)
    
    # ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
    print("\nğŸ“‚ ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª...")
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42
    )
    print(f"Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨: {len(X_train)}")
    print(f"Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±: {len(X_test)}")
    
    # Ø¨Ù†Ø§Ø¡ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬
    results = build_models(X_train, X_test, y_train, y_test)
    
    # Ø¹Ø±Ø¶ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
    print_results(results)
    
    # ØªØµÙˆØ± Ø§Ù„Ù†ØªØ§Ø¦Ø¬
    visualize_results(results, y_test)
    
    # ØªØ­Ù„ÙŠÙ„ Ø£Ù‡Ù…ÙŠØ© Ø§Ù„Ù…ÙŠØ²Ø§Øª
    feature_importance(results, feature_cols)
    
    print("\nâœ… Ø§ÙƒØªÙ…Ù„ Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø¨Ù†Ø¬Ø§Ø­!")
    
    # Ø­ÙØ¸ Ø£ÙØ¶Ù„ Ù†Ù…ÙˆØ°Ø¬
    best_model_name = max(results, key=lambda x: results[x]['test_r2'])
    best_model = results[best_model_name]['model']
    
    import pickle
    with open(r'c:\Users\gerge\OneDrive\Ø³Ø·Ø­ Ø§Ù„Ù…ÙƒØªØ¨\VSCODE\c++\AI\best_delay_model.pkl', 'wb') as f:
        pickle.dump(best_model, f)
    print(f"\nğŸ’¾ ØªÙ… Ø­ÙØ¸ Ø£ÙØ¶Ù„ Ù†Ù…ÙˆØ°Ø¬ ({best_model_name}) ÙÙŠ 'best_delay_model.pkl'")

if __name__ == "__main__":
    main()
